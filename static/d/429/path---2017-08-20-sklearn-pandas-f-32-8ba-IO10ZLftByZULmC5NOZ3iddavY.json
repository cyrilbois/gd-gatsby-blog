{"data":{"site":{"siteMetadata":{"title":"Giacomo Debidda","author":"Giacomo Debidda"}},"markdownRemark":{"id":"3395a177-fa67-5479-9e60-499870f4c075 >>> MarkdownRemark","excerpt":"sklearn-pandas  is a small library that provides a bridge between  scikit-learn ’s machine learning methods and pandas Data Frames. In this…","html":"<p><a href=\"https://github.com/pandas-dev/sklearn-pandas\">sklearn-pandas</a> is a small library that provides a bridge between <a href=\"https://github.com/scikit-learn/scikit-learn\">scikit-learn</a>’s machine learning methods and pandas Data Frames.</p>\n<p>In this blog post I will show you a simple example on how to use sklearn-pandas in a classification problem. I will use the Titanic dataset from Kaggle. You can find training set e test set <a href=\"https://www.kaggle.com/c/titanic/data\">here</a>.</p>\n<h2>Imports</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">import</span> LabelBinarizer<span class=\"token punctuation\">,</span> Imputer<span class=\"token punctuation\">,</span> LabelEncoder<span class=\"token punctuation\">,</span> \\\n    FunctionTransformer<span class=\"token punctuation\">,</span> Binarizer<span class=\"token punctuation\">,</span> StandardScaler<span class=\"token punctuation\">,</span> MultiLabelBinarizer\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>pipeline <span class=\"token keyword\">import</span> Pipeline\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>ensemble <span class=\"token keyword\">import</span> RandomForestClassifier\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> StratifiedKFold<span class=\"token punctuation\">,</span> cross_val_score\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> accuracy_score\n<span class=\"token keyword\">from</span> sklearn_pandas <span class=\"token keyword\">import</span> DataFrameMapper<span class=\"token punctuation\">,</span> CategoricalImputer\n\n\nhere <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>abspath<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>dirname<span class=\"token punctuation\">(</span>__file__<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Data</h2>\n<p>Kaggle provides separate files for training set e test set: <code class=\"language-text\">trains.csv</code> contains class labels (0 = dead; 1 = survived), while <code class=\"language-text\">test.csv</code> does not.</p>\n<p>If you want you can perform some basic EDA (Exploratory Data Analysis). Be careful of <a href=\"https://www.quora.com/Whats-data-leakage-in-data-science\">data leakege</a> though! Don’t use test data to carry on EDA, otherwise you will be tempted to select some features or perform some operations based on what you see on the test data. Here I will concatenate training set and test set just to see the total number of samples and the missing values of the entire dataset. I will “touch” the test set only at the end, for prediction.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">data_directory <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>abspath<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>here<span class=\"token punctuation\">,</span> <span class=\"token string\">'data'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'titanic'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ntrain_csv <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>data_directory<span class=\"token punctuation\">,</span> <span class=\"token string\">'train.csv'</span><span class=\"token punctuation\">)</span>\ntest_csv <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>data_directory<span class=\"token punctuation\">,</span> <span class=\"token string\">'test.csv'</span><span class=\"token punctuation\">)</span>\n\ndf_train <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span>train_csv<span class=\"token punctuation\">,</span> header<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> index_col<span class=\"token operator\">=</span><span class=\"token string\">'PassengerId'</span><span class=\"token punctuation\">)</span>\ndf_test <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span>test_csv<span class=\"token punctuation\">,</span> header<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> index_col<span class=\"token operator\">=</span><span class=\"token string\">'PassengerId'</span><span class=\"token punctuation\">)</span>\ndf <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>concat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>df_train<span class=\"token punctuation\">,</span> df_test<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> keys<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'train'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'test'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'--- Info ---'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">.</span>info<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'--- Describe ---'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">.</span>describe<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'--- Features ---'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">for</span> feature <span class=\"token keyword\">in</span> <span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>df_train<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>difference<span class=\"token punctuation\">(</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>feature<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">[</span>feature<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>value_counts<span class=\"token punctuation\">(</span>dropna<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'-'</span> <span class=\"token operator\">*</span> <span class=\"token number\">40</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Features</h2>\n<p>When working on a machine learning problem, feature engineering is manually <a href=\"https://www.quora.com/What-is-feature-engineering/answer/Tomasz-Malisiewicz?srid=tdBp\">designing what the input x’s should be</a>.</p>\n<p>With sklearn-pandas you can use the <code class=\"language-text\">DataFrameMapper</code> class to declare transformations and variable imputations.</p>\n<p><code class=\"language-text\">default=False</code> means that only the variables specified in the <code class=\"language-text\">DataFrameMapper</code> will be kept. All other variables will be discarded.</p>\n<p><code class=\"language-text\">None</code> means that no transformation will be applied to that variable.</p>\n<p><code class=\"language-text\">LabelBinarizer</code> converts a categorical variable into a <em>dummy variable</em> (aka <em>binary variable</em>). A dummy variable is either 1 or 0, whether a condition is met or not (in pandas categorical variables can be converted into dummy variables with the method <a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html\">get_dummies</a>).</p>\n<p><code class=\"language-text\">Imputer</code> is a scikit-learn class that can perform NA imputation for quantitative variables, while <code class=\"language-text\">CategoricalImputer</code> is a sklearn-pandas class that works on categorical variables too. <a href=\"https://en.wikipedia.org/wiki/Imputation_(statistics)\">Missing value imputation</a> is a broad topic, and in other languages there are entire packages dedicated to it. For example, in R you can find <a href=\"https://www.r-bloggers.com/imputing-missing-data-with-r-mice-package/\">MICE</a> and <a href=\"https://github.com/IQSS/Amelia\">Amelia</a>.</p>\n<p>In a <code class=\"language-text\">DataFrameMapper</code> you can also provide a custom name for the transformed features – to be used instead of the automatically generated one – by specifying it as the third argument of the feature definition.</p>\n<p>The difference between specifying the column selector as <code class=\"language-text\">&#39;column&#39;</code> (as a simple string) and <code class=\"language-text\">[&#39;column&#39;]</code> (as a list with one element is the shape of the array that is passed to the transformer. In the first case, a one dimensional array will be passed, while in the second case it will be a 2-dimensional array with one column, i.e. a column vector.</p>\n<p><em>Example:</em> with a simple string <code class=\"language-text\">Imputer()</code> will discard <code class=\"language-text\">NaN</code> values for the column <code class=\"language-text\">Age</code>, and the fitting process will fail because of a mismatch of the size of this array and the other arrays in the <code class=\"language-text\">DataFrame</code>.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">mapper <span class=\"token operator\">=</span> DataFrameMapper<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">'Pclass'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">'Sex'</span><span class=\"token punctuation\">,</span> LabelBinarizer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Age'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>Imputer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">'SibSp'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'alias'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'Some variable'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Ticket'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>LabelBinarizer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Fare'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> Imputer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">'Embarked'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>CategoricalImputer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> MultiLabelBinarizer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> default<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Once again, here is how to use <code class=\"language-text\">DataMapper</code>:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">mapper <span class=\"token operator\">=</span> DataFrameMapper<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Age'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>Imputer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># OK</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">'Age'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>Imputer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># NO!</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Pipeline</h2>\n<p>Now that the you defined the features you want to use, you can build a scikit-learn <code class=\"language-text\">Pipeline</code>. The first step of the Pipeline is the <code class=\"language-text\">mapper</code> you have just defined. The last step is a scikit-learn <code class=\"language-text\">Estimator</code> that will run the classification. In this case I chose a <code class=\"language-text\">RandomForestClassifier</code> with a basic configuration. Between these two steps you can define additional ones. For example, you might want to <a href=\"https://en.wikipedia.org/wiki/Standard_score\">z-normalize</a> your features with a <code class=\"language-text\">StandardScaler</code>.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">pipeline <span class=\"token operator\">=</span> Pipeline<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">'feature_mapper'</span><span class=\"token punctuation\">,</span> mapper<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">'scaler'</span><span class=\"token punctuation\">,</span> StandardScaler<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">'classifier'</span><span class=\"token punctuation\">,</span> RandomForestClassifier<span class=\"token punctuation\">(</span>n_estimators<span class=\"token operator\">=</span><span class=\"token number\">50</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span>seed<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Cross validation</h2>\n<p>The pipeline is ready, so you can train your model. In order to provide several estimates of the model’s accuracy you can use cross validation. scikit-learn provides the convenient function <code class=\"language-text\">cross_val_score</code> to do that, but you can also do it manually. Keep in mind that we are not touching the test set here: <code class=\"language-text\">xx_train</code> and <code class=\"language-text\">xx_test</code> are both part of the entire training set. We just split the entire training set to train it on <code class=\"language-text\">xx_train</code> and predict on <code class=\"language-text\">xx_test</code>.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">x_train <span class=\"token operator\">=</span> df_train<span class=\"token punctuation\">[</span>df_train<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Survived'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\ny_train <span class=\"token operator\">=</span> df_train<span class=\"token punctuation\">[</span><span class=\"token string\">'Survived'</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># one way of computing cross-validated accuracy estimates</span>\nskf <span class=\"token operator\">=</span> StratifiedKFold<span class=\"token punctuation\">(</span>n_splits<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> shuffle<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span>seed<span class=\"token punctuation\">)</span>\nscores <span class=\"token operator\">=</span> cross_val_score<span class=\"token punctuation\">(</span>pipeline<span class=\"token punctuation\">,</span> x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> cv<span class=\"token operator\">=</span>skf<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Accuracy estimates: {}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>scores<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># another way of computing cross-validated accuracy estimates</span>\n<span class=\"token keyword\">for</span> i_split<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>ii_train<span class=\"token punctuation\">,</span> ii_test<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>skf<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>X<span class=\"token operator\">=</span>x_train<span class=\"token punctuation\">,</span> y<span class=\"token operator\">=</span>y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># x_train (independent variables, aka features) is a pandas DataFrame.</span>\n    <span class=\"token comment\"># xx_train and xx_test are pandas dataframes</span>\n    xx_train <span class=\"token operator\">=</span> x_train<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span>ii_train<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\n    xx_test <span class=\"token operator\">=</span> x_train<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span>ii_test<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\n    <span class=\"token comment\"># y_train (target variable) is a pandas Series.</span>\n    <span class=\"token comment\"># yy_train and yy_test are numpy arrays</span>\n    yy_train <span class=\"token operator\">=</span> y_train<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">[</span>ii_train<span class=\"token punctuation\">]</span>\n    yy_test <span class=\"token operator\">=</span> y_train<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">[</span>ii_test<span class=\"token punctuation\">]</span>\n\n    model <span class=\"token operator\">=</span> pipeline<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X<span class=\"token operator\">=</span>xx_train<span class=\"token punctuation\">,</span> y<span class=\"token operator\">=</span>yy_train<span class=\"token punctuation\">)</span>\n    predictions <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>xx_test<span class=\"token punctuation\">)</span>\n    score <span class=\"token operator\">=</span> accuracy_score<span class=\"token punctuation\">(</span>y_true<span class=\"token operator\">=</span>yy_test<span class=\"token punctuation\">,</span> y_pred<span class=\"token operator\">=</span>predictions<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Accuracy of split num {}: {}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>i_split<span class=\"token punctuation\">,</span> score<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># final model (retrain it on the entire train set)</span>\nmodel <span class=\"token operator\">=</span> pipeline<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X<span class=\"token operator\">=</span>x_train<span class=\"token punctuation\">,</span> y<span class=\"token operator\">=</span>y_train<span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Predict</h2>\n<p>Now that the model is trained we can finally predict data that we have never seen before (i.e. the test set).</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># In this problem df_test doesn't contain the target variable 'Survived'</span>\nx_test <span class=\"token operator\">=</span> df_test\npredictions <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Predictions (0 = dead, 1 = survived)'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>predictions<span class=\"token punctuation\">)</span></code></pre></div>\n<h2>The entire script</h2>\n<p>Here is the entire script:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">import</span> LabelBinarizer<span class=\"token punctuation\">,</span> Imputer<span class=\"token punctuation\">,</span> LabelEncoder<span class=\"token punctuation\">,</span> \\\n    FunctionTransformer<span class=\"token punctuation\">,</span> Binarizer<span class=\"token punctuation\">,</span> StandardScaler<span class=\"token punctuation\">,</span> MultiLabelBinarizer\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>pipeline <span class=\"token keyword\">import</span> Pipeline\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>ensemble <span class=\"token keyword\">import</span> RandomForestClassifier\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> StratifiedKFold<span class=\"token punctuation\">,</span> cross_val_score\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> accuracy_score\n<span class=\"token keyword\">from</span> sklearn_pandas <span class=\"token keyword\">import</span> DataFrameMapper<span class=\"token punctuation\">,</span> CategoricalImputer\n\n\nhere <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>abspath<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>dirname<span class=\"token punctuation\">(</span>__file__<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span>seed<span class=\"token operator\">=</span><span class=\"token number\">42</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    data_directory <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>abspath<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>here<span class=\"token punctuation\">,</span> <span class=\"token string\">'data'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'titanic'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    train_csv <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>data_directory<span class=\"token punctuation\">,</span> <span class=\"token string\">'train.csv'</span><span class=\"token punctuation\">)</span>\n    test_csv <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>data_directory<span class=\"token punctuation\">,</span> <span class=\"token string\">'test.csv'</span><span class=\"token punctuation\">)</span>\n\n    df_train <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span>train_csv<span class=\"token punctuation\">,</span> header<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> index_col<span class=\"token operator\">=</span><span class=\"token string\">'PassengerId'</span><span class=\"token punctuation\">)</span>\n    df_test <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span>test_csv<span class=\"token punctuation\">,</span> header<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> index_col<span class=\"token operator\">=</span><span class=\"token string\">'PassengerId'</span><span class=\"token punctuation\">)</span>\n    df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>concat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>df_train<span class=\"token punctuation\">,</span> df_test<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> keys<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'train'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'test'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'--- Info ---'</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">.</span>info<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'--- Describe ---'</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">.</span>describe<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'--- Features ---'</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> feature <span class=\"token keyword\">in</span> <span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>df_train<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>difference<span class=\"token punctuation\">(</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>feature<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">[</span>feature<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>value_counts<span class=\"token punctuation\">(</span>dropna<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'-'</span> <span class=\"token operator\">*</span> <span class=\"token number\">40</span><span class=\"token punctuation\">)</span>\n\n    mapper <span class=\"token operator\">=</span> DataFrameMapper<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n        <span class=\"token punctuation\">(</span><span class=\"token string\">'Pclass'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">(</span><span class=\"token string\">'Sex'</span><span class=\"token punctuation\">,</span> LabelBinarizer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Age'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>Imputer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">(</span><span class=\"token string\">'SibSp'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'alias'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'Some variable'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Ticket'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>LabelBinarizer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Fare'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> Imputer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">(</span><span class=\"token string\">'Embarked'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>CategoricalImputer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> MultiLabelBinarizer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> default<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n\n    pipeline <span class=\"token operator\">=</span> Pipeline<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n        <span class=\"token punctuation\">(</span><span class=\"token string\">'feature_mapper'</span><span class=\"token punctuation\">,</span> mapper<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">(</span><span class=\"token string\">'scaler'</span><span class=\"token punctuation\">,</span> StandardScaler<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">(</span><span class=\"token string\">'classifier'</span><span class=\"token punctuation\">,</span> RandomForestClassifier<span class=\"token punctuation\">(</span>n_estimators<span class=\"token operator\">=</span><span class=\"token number\">50</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span>seed<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    x_train <span class=\"token operator\">=</span> df_train<span class=\"token punctuation\">[</span>df_train<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Survived'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n    y_train <span class=\"token operator\">=</span> df_train<span class=\"token punctuation\">[</span><span class=\"token string\">'Survived'</span><span class=\"token punctuation\">]</span>\n\n    <span class=\"token comment\"># one way of computing cross-validated accuracy estimates</span>\n    skf <span class=\"token operator\">=</span> StratifiedKFold<span class=\"token punctuation\">(</span>n_splits<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> shuffle<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span>seed<span class=\"token punctuation\">)</span>\n    scores <span class=\"token operator\">=</span> cross_val_score<span class=\"token punctuation\">(</span>pipeline<span class=\"token punctuation\">,</span> x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> cv<span class=\"token operator\">=</span>skf<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Accuracy estimates: {}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>scores<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># another way of computing cross-validated accuracy estimates</span>\n    <span class=\"token keyword\">for</span> i_split<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>ii_train<span class=\"token punctuation\">,</span> ii_test<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>skf<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>X<span class=\"token operator\">=</span>x_train<span class=\"token punctuation\">,</span> y<span class=\"token operator\">=</span>y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># x_train (independent variables, aka features) is a pandas DataFrame.</span>\n        <span class=\"token comment\"># xx_train and xx_test are pandas dataframes</span>\n        xx_train <span class=\"token operator\">=</span> x_train<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span>ii_train<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\n        xx_test <span class=\"token operator\">=</span> x_train<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span>ii_test<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\n        <span class=\"token comment\"># y_train (target variable) is a pandas Series.</span>\n        <span class=\"token comment\"># yy_train and yy_test are numpy arrays</span>\n        yy_train <span class=\"token operator\">=</span> y_train<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">[</span>ii_train<span class=\"token punctuation\">]</span>\n        yy_test <span class=\"token operator\">=</span> y_train<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">[</span>ii_test<span class=\"token punctuation\">]</span>\n\n        model <span class=\"token operator\">=</span> pipeline<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X<span class=\"token operator\">=</span>xx_train<span class=\"token punctuation\">,</span> y<span class=\"token operator\">=</span>yy_train<span class=\"token punctuation\">)</span>\n        predictions <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>xx_test<span class=\"token punctuation\">)</span>\n        score <span class=\"token operator\">=</span> accuracy_score<span class=\"token punctuation\">(</span>y_true<span class=\"token operator\">=</span>yy_test<span class=\"token punctuation\">,</span> y_pred<span class=\"token operator\">=</span>predictions<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Accuracy of split num {}: {}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>i_split<span class=\"token punctuation\">,</span> score<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># final model (retrain it on the entire train set)</span>\n    model <span class=\"token operator\">=</span> pipeline<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X<span class=\"token operator\">=</span>x_train<span class=\"token punctuation\">,</span> y<span class=\"token operator\">=</span>y_train<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># In this problem df_test doesn't contain the target variable 'Survived'</span>\n    x_test <span class=\"token operator\">=</span> df_test\n    predictions <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Predictions (0 = dead, 1 = survived)'</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>predictions<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span>\n    main<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>If you run it, you should get these results with <code class=\"language-text\">seed=42</code>:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">Accuracy estimates: [ 0.7979798   0.83501684  0.81144781]\nAccuracy of split num 0: 0.797979797979798\nAccuracy of split num 1: 0.835016835016835\nAccuracy of split num 2: 0.8114478114478114\nPredictions (0 = dead, 1 = survived)\n[0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0\n 1 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n 1 1 0 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n 0 0 1 0 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1\n 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1\n 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0\n 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n 0 1 1 1 1 0 0 1 0 0 0]</code></pre></div>","frontmatter":{"title":"sklearn-pandas","date":"August 20, 2017"}}},"pageContext":{"slug":"/2017-08-20-sklearn-pandas/","previous":{"fields":{"slug":"/2017-08-07-quickstart-python-projects-with-invoke/"},"frontmatter":{"title":"Quickstart Python projects with Invoke"}},"next":{"fields":{"slug":"/2017-08-29-a-few-timeless-lessons-from-peopleware/"},"frontmatter":{"title":"A few timeless lessons from Peopleware"}}}}