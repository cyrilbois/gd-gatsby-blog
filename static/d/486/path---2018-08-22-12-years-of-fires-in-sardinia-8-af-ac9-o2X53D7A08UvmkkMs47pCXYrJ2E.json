{"data":{"site":{"siteMetadata":{"title":"Giacomo Debidda","author":"Giacomo Debidda"}},"markdownRemark":{"id":"b2b9e476-55a9-5b5b-81da-af3589ec7426 >>> MarkdownRemark","excerpt":"This summer I was looking for some data visualization challenges and I came across  this cool project  by Mauro Melis. Mauro created it for…","html":"<p>This summer I was looking for some data visualization challenges and I came across <a href=\"https://mauromelis.gitlab.io/sardinia-on-fire/\">this cool project</a> by Mauro Melis. Mauro created it for a contest organized by <a href=\"http://contest.formez.it/\">Open Data Sardegna</a>, and the jury found it so cool that he won the first prize in the data visualization category.</p>\n<p>It’s basically a <a href=\"https://flowingdata.com/tag/scrollytelling/\">scrollytelling</a> visualization, a type of visualization popularized - among others - by <a href=\"https://www.nytimes.com/interactive/2016/12/07/world/asia/rodrigo-duterte-philippines-drugs-killings.html\">The New York Times</a> and the guys at <a href=\"https://pudding.cool/\">The Pudding</a>.</p>\n<p>There were no links to the data that Mauro used, but it was pretty easy to find the datasets from <a href=\"http://dati.regione.sardegna.it/dataset/cfva-perimetrazioni-aree-percorse-dal-fuoco-2005\">2005</a> to <a href=\"http://dati.regione.sardegna.it/dataset/cfva-perimetrazioni-aree-percorse-dal-fuoco-2016\">2016</a>, namely 12 years of wild fires in Sardinia.</p>\n<p>I like scrollytelling, but I wanted to do something quick this time. I also wanted to try an online tool (it’s also a library, but I used the online tool) developed by Uber: <a href=\"http://kepler.gl/#/\">Kepler.gl</a>.</p>\n<h2>Shapefiles? GeoPandas!</h2>\n<p>The datasets from 2005 to 2016 contain <a href=\"https://en.wikipedia.org/wiki/Shapefile\">shapefiles</a>, a popular geospatial vector data format. I know that there are several <a href=\"https://www.sitepoint.com/javascript-geospatial-advanced-maps/\">geospatial libraries in Javascript</a>, and of course <a href=\"https://medium.com/@mbostock/command-line-cartography-part-1-897aa8f8ca2c\">D3 is awesome for creating maps</a>, but I think that Python is so much better at data wrangling than Javascript, so I decided to go with it.</p>\n<p>In Python, if you need to work with data, you pick Pandas.</p>\n<p>If you need to work with Geospatial data, you pick GeoPandas.</p>\n<p>It’s that simple!</p>\n<h2>Not much Data Wrangling</h2>\n<p>Turns out that these datasets were actually pretty good, so I didn’t have to do too much data wrangling. Of course there were differences from year to year, but nothing major. As an example, this is what I did to clean the 2016 dataset:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> geopandas <span class=\"token keyword\">as</span> gpd\n\ngdf2016 <span class=\"token operator\">=</span> gpd<span class=\"token punctuation\">.</span>read_file<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>data_dir<span class=\"token punctuation\">,</span> <span class=\"token string\">'areeIncendiatePerim2016'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Perimetri_Superfici_Bruciate_2016.shp'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ngdf2016 <span class=\"token operator\">=</span> gdf2016\\\n    <span class=\"token punctuation\">.</span>reset_index<span class=\"token punctuation\">(</span>drop<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\\\n    <span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span>columns<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'BASE_FID'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ID_INCE'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ISTAT'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ID_PROV'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'STIR'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'STAZIONE'</span><span class=\"token punctuation\">,</span>\n                   <span class=\"token string\">'COMUNE'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'TIPOLOGIE'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'M2_BOSCO'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'M2_PASCOLO'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'M2_ALTRO'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'SUP_TOT_M2'</span><span class=\"token punctuation\">,</span>\n                   <span class=\"token string\">'TIPO_INCE'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'dist_ins'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ID_RILIEVO'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'MODIFICHE'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\\\n    <span class=\"token punctuation\">.</span>rename<span class=\"token punctuation\">(</span>columns<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">'TOPONIMO'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'toponym'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'DATA_INCE'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'date'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'N_INCE'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'num_fires'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'SUP_TOT_HA'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'hectars'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n\ncols <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'toponym'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'hectars'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'date'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'num_fires'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'geometry'</span><span class=\"token punctuation\">]</span>\ngdf2016 <span class=\"token operator\">=</span> gdf2016<span class=\"token punctuation\">[</span>cols<span class=\"token punctuation\">]</span></code></pre></div>\n<p>Basically I harmonized the datasets from 2005 to 2016, so they had the same structure.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">gdf2016<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><img src=\"./gdf-head.png\" alt=\"GeoFataFrame head() method\" title=\"gdf.head()\"></p>\n<p>Then I concatenated everything:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">gdf <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>concat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>gdf2005<span class=\"token punctuation\">,</span> gdf2006<span class=\"token punctuation\">,</span> gdf2007<span class=\"token punctuation\">,</span>\n                 gdf2008<span class=\"token punctuation\">,</span> gdf2009<span class=\"token punctuation\">,</span> gdf2010<span class=\"token punctuation\">,</span>\n                 gdf2011<span class=\"token punctuation\">,</span> gdf2012<span class=\"token punctuation\">,</span> gdf2013<span class=\"token punctuation\">,</span>\n                 gdf2014<span class=\"token punctuation\">,</span> gdf2015<span class=\"token punctuation\">,</span> gdf2016<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>I experimented a little bit with <a href=\"http://geoviews.org/\">GeoViews</a> in a Jupyter notebook…</p>\n<p><img src=\"./experiments.png\" alt=\"Experiments with GeoViews\" title=\"Experiments with GeoViews\"></p>\n<h2>Simplify (after all, <a href=\"https://en.wikipedia.org/wiki/Ludwig_Mies_van_der_Rohe\">Less is More</a>)</h2>\n<p>I exported everything with:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">df<span class=\"token punctuation\">.</span>to_csv<span class=\"token punctuation\">(</span><span class=\"token string\">'sardinia_fires.csv'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>While this worked, it resulted in a ~150MB CSV file. This is because I was including in the output the geometries of all the polygons. I uploaded the CSV file to Kepler.gl and it actually worked (well, I wasn’t exactly surprised given that Kepler was developed to visualize Uber’s data), but it took some time (I think ~10 minutes to upload).</p>\n<p>I explored the data in <a href=\"http://kepler.gl/#/demo\">Kepler.gl</a> for a couple of minutes. The vast majority of the wild fires in these datasets were quite small, so they looked like points. I decided to get rid of the <code class=\"language-text\">geometry</code> column in the <code class=\"language-text\">GeoDataFrame</code> and to export only the coordinates of the centroid of each polygon. This was super easy to do with GeoPandas:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">gdf<span class=\"token punctuation\">[</span><span class=\"token string\">'CentroidLongitude'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> gdf<span class=\"token punctuation\">[</span><span class=\"token string\">'geometry'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> poly<span class=\"token punctuation\">:</span> poly<span class=\"token punctuation\">.</span>centroid<span class=\"token punctuation\">.</span>bounds<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ngdf<span class=\"token punctuation\">[</span><span class=\"token string\">'CentroidLatitude'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> gdf<span class=\"token punctuation\">[</span><span class=\"token string\">'geometry'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> poly<span class=\"token punctuation\">:</span> poly<span class=\"token punctuation\">.</span>centroid<span class=\"token punctuation\">.</span>bounds<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>The resulting CSV file was obviously much smaller.</p>\n<p>I decided to use the following <a href=\"https://blog.qlik.com/visual-encoding\">visual encoding</a> for the points (well, circles):</p>\n<ul>\n<li>color correlates with number of fires (yellow = less fires; purple = more fires)</li>\n<li>size correlates with area (in hectares).</li>\n</ul>\n<h2>Success!</h2>\n<p>I took a screenshot:</p>\n<p><img src=\"./sardinia-fires.png\" alt=\"12 Years of fire in Sardinia, screenshot\" title=\"12 Years of fire in Sardinia\"></p>\n<p>and an animated GIF (I recorded it with <a href=\"https://github.com/phw/peek\">Peek</a>, a really amazing tool):</p>\n<p><img src=\"./sardinia-fires.gif\" alt=\"12 Years of fire in Sardinia, GIF\" title=\"12 Years of fire in Sardinia\"></p>\n<p>I posted it on the <a href=\"https://www.reddit.com/r/dataisbeautiful/comments/8z1i0p/12_years_of_fires_in_sardinia_20052016_oc/\">DataIsBeautiful subreddit</a> and it was quite succesfull.</p>\n<p>Someone commented that I should have added a legend, and I agree, but apparently I was too lazy to find out how to add it in Kepler.gl.</p>\n<p>Other projects where I had to do much more data wrangling had been completely ignored.</p>\n<p>Lessons learned:</p>\n<ul>\n<li>Nobody cares about how much you struggled with data wrangling (but you still have to do it).</li>\n<li>Always include a GIF in a README (well, I already knew that…)</li>\n<li>Sardinian cities keep their Italian name in English</li>\n</ul>\n<h2>Code</h2>\n<p>You can find the <a href=\"https://github.com/jackdbd/sardinia-fires\">repository on GitHub</a>.</p>\n<h2>A Note on Reproducibilty</h2>\n<p>I recently tried to reproduce the notebook and I had to exclude the dataset from 2010. I think this is due to some dependency issues with <a href=\"https://macwright.org/2012/10/31/gis-with-python-shapely-fiona.html\">fiona</a>, which is used by GeoPandas.</p>","frontmatter":{"title":"12 Years of Fires in Sardinia","date":"August 22, 2018"}}},"pageContext":{"slug":"/2018-08-22-12-years-of-fires-in-sardinia/","previous":{"fields":{"slug":"/2018-08-21-export-a-geodataframe-to-spatialite/"},"frontmatter":{"title":"Export a GeoDataFrame to Spatialite"}},"next":null}}